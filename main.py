import streamlit as st
import pandas as pd
from openai import OpenAI
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from collections import Counter
from wordcloud import WordCloud
from io import BytesIO
from PIL import Image
import openai
import datetime
import re

# --- ê¸°ë³¸ ì„¤ì • (ìˆ˜ì • ì—†ìŒ) ---
FONT_PATH = "NanumGothic-Regular.ttf"
plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
st.set_page_config(page_title="SAM ë¶„ì„ ë³´ê³ ì„œ", layout="wide")  # ë„“ì€ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë³€ê²½

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
st.sidebar.header("âš™ï¸ ë¶„ì„ ì„¤ì •")

# 1. ê¸°ë³¸ íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.sidebar.file_uploader("1. ì§ˆë¬¸/ë‹µë³€ ë°ì´í„° ì—…ë¡œë“œ",
                                         type=["csv", "xlsx"])

# df_learningì„ ì„¸ì…˜ ìƒíƒœì— ì´ˆê¸°í™”
if 'df_learning' not in st.session_state:
    st.session_state.df_learning = None

# 2. ë¶„ì„ ëª¨ë“œ ì„ íƒ
analysis_mode = st.sidebar.radio("2. ë¶„ì„ ëª¨ë“œ ì„ íƒ",
                                 ('ìˆ˜ê°• ì´ë ¥ ì—†ì´ ì§ˆë¬¸ ë‚´ì—­ë§Œìœ¼ë¡œ ì¡°íšŒ', 'ìˆ˜ê°• ì´ë ¥ ì—…ë¡œë“œ í›„ í•¨ê»˜ ë¶„ì„'))

# 3. ì¡°ê±´ë¶€ë¡œ ìˆ˜ê°• ì´ë ¥ íŒŒì¼ ì—…ë¡œë“œ
if analysis_mode == 'ìˆ˜ê°• ì´ë ¥ ì—…ë¡œë“œ í›„ í•¨ê»˜ ë¶„ì„':
    learning_file_main = st.sidebar.file_uploader("3. ìˆ˜ê°• ì´ë ¥ ë°ì´í„° ì—…ë¡œë“œ",
                                                  type=["csv", "xlsx"],
                                                  key="main_learning_uploader")
    if learning_file_main:
        try:
            if learning_file_main.name.endswith(".csv"):
                st.session_state.df_learning = pd.read_csv(learning_file_main)
            else:
                st.session_state.df_learning = pd.read_excel(
                    learning_file_main)
            st.sidebar.success("âœ… ìˆ˜ê°• ì´ë ¥ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            st.sidebar.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            st.session_state.df_learning = None
else:
    st.session_state.df_learning = None

st.sidebar.markdown("---")
st.sidebar.info("ëª¨ë“  ì„¤ì •ì„ ì™„ë£Œí•œ í›„, ìš°ì¸¡ í™”ë©´ì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# --- ë©”ì¸ í™”ë©´ êµ¬ì„± ---
st.title("ğŸ“„ SAM ë¶„ì„ ë³´ê³ ì„œ")

if uploaded_file:
    try:
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)

        # --- ì´ ì•„ë˜ë¶€í„°ëŠ” ê¸°ì¡´ íƒ­ ì½”ë“œì™€ ë™ì¼ ---
        # (ë‹¨, tab5, tab6 ë‚´ë¶€ì˜ íŒŒì¼ ì—…ë¡œë”ëŠ” ì œê±°ëœ ìµœì¢… ë²„ì „ ê¸°ì¤€)

        # ì¡°ì‚¬ê¸°ê°„ ì²˜ë¦¬
        if 'regymdt' in df.columns:
            df['regymdt'] = pd.to_datetime(df['regymdt'], errors='coerce')
            start_date = df['regymdt'].min().strftime("%Y-%m-%d")
            end_date = df['regymdt'].max().strftime("%Y-%m-%d")
        else:
            start_date = end_date = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

        # ì´ ì°¸ì—¬ì
        if 'user_id' in df.columns:
            total_users = df['user_id'].nunique()
        else:
            total_users = 0

        # ì´ ì§ˆë¬¸ ìˆ˜
        if 'question' in df.columns:
            total_questions = df['question'].notnull().sum()
        else:
            total_questions = 0

        # íƒ­ êµ¬ì„±
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
            ["ğŸ“Œ ë¶„ì„ ê°œìš”", "ğŸ¢ ì¡°ì§ë³„ í˜„í™©", "â“ ì§ˆë¬¸ í˜„í™©", "ğŸ§  ë‹µë³€ ë¶„ì„", "ğŸ‘¤ì´ìš©ì ë¶„ì„", "ğŸ“Š ì‹¤í—˜ì‹¤"])

        # (Tab1, Tab2, Tab3, Tab4 ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ)
        with tab1:
            st.subheader("ğŸ“Œ ë¶„ì„ ê°œìš”")
            st.markdown(f"- **ì¡°ì‚¬ê¸°ê°„**: {start_date} ~ {end_date}")
            st.markdown(f"- **ì´ ì°¸ì—¬ì**: {total_users}ëª…")
            st.markdown(f"- **ì´ ì§ˆë¬¸ ìˆ˜**: {total_questions}ê±´")

        with tab2:
            st.subheader("ğŸ¢ ì¡°ì§ë³„ í˜„í™©")

            if all(col in df.columns
                   for col in ['group_1', 'group_2', 'group_3', 'user_id']):

                # 1. ì•ˆë‚´ ë©”ì‹œì§€ ë° í•œ ì¤„ ë ˆì´ì•„ì›ƒ
                st.info("ì¡°ì§ì„ ìˆœì„œëŒ€ë¡œ ì„ íƒí•˜ì—¬ í•„í„°ë§í•˜ê³ , ì•„ë˜ ê¸°ì¤€ì„ ì„ íƒí•˜ì—¬ ë°ì´í„°ë¥¼ ì§‘ê³„í•©ë‹ˆë‹¤.")
                col1, col2, col3 = st.columns(3)

                # --- ê³„ì¸µì  ì¡°ì§ í•„í„° ---
                with col1:
                    group1_options = ['ì „ì²´'] + sorted(
                        df['group_1'].dropna().unique().tolist())
                    selected_group1 = st.selectbox("1ï¸âƒ£ 1ì°¨ ì¡°ì§ (ì„¼í„°)",
                                                   options=group1_options)

                df_filtered = df.copy()
                if selected_group1 != 'ì „ì²´':
                    df_filtered = df_filtered[df_filtered['group_1'] ==
                                              selected_group1]

                with col2:
                    group2_options = ['ì „ì²´'] + sorted(
                        df_filtered['group_2'].dropna().unique().tolist())
                    selected_group2 = st.selectbox("2ï¸âƒ£ 2ì°¨ ì¡°ì§ (ì‹¤)",
                                                   options=group2_options)

                if selected_group2 != 'ì „ì²´':
                    df_filtered = df_filtered[df_filtered['group_2'] ==
                                              selected_group2]

                with col3:
                    group3_options = ['ì „ì²´'] + sorted(
                        df_filtered['group_3'].dropna().unique().tolist())
                    selected_group3 = st.selectbox("3ï¸âƒ£ 3ì°¨ ì¡°ì§ (íŒ€)",
                                                   options=group3_options)

                if selected_group3 != 'ì „ì²´':
                    df_filtered = df_filtered[df_filtered['group_3'] ==
                                              selected_group3]

                st.markdown("---")

                # 2. ë™ì  ë¼ë””ì˜¤ ë²„íŠ¼ ë¡œì§
                group_labels = {
                    'ì„¼í„° ê¸°ì¤€': 'group_1',
                    'ì‹¤ ê¸°ì¤€': 'group_2',
                    'íŒ€ ê¸°ì¤€': 'group_3'
                }

                # ì„ íƒëœ ì¡°ì§ ë ˆë²¨ì— ë”°ë¼ ë¼ë””ì˜¤ ë²„íŠ¼ ì˜µì…˜ê³¼ ê¸°ë³¸ê°’ì„ ë™ì ìœ¼ë¡œ ê²°ì •
                if selected_group3 != 'ì „ì²´':
                    # 3ì°¨ ì¡°ì§ ì„ íƒ ì‹œ: 'íŒ€ ê¸°ì¤€'ë§Œ ê°€ëŠ¥
                    radio_options = ['íŒ€ ê¸°ì¤€']
                    radio_index = 0
                elif selected_group2 != 'ì „ì²´':
                    # 2ì°¨ ì¡°ì§ ì„ íƒ ì‹œ: 'ì‹¤ ê¸°ì¤€', 'íŒ€ ê¸°ì¤€' ê°€ëŠ¥
                    radio_options = ['ì‹¤ ê¸°ì¤€', 'íŒ€ ê¸°ì¤€']
                    radio_index = 0
                else:
                    # ì „ì²´ ë˜ëŠ” 1ì°¨ ì¡°ì§ ì„ íƒ ì‹œ: ëª¨ë“  ê¸°ì¤€ ê°€ëŠ¥
                    radio_options = ['ì„¼í„° ê¸°ì¤€', 'ì‹¤ ê¸°ì¤€', 'íŒ€ ê¸°ì¤€']
                    radio_index = 0

                selected_label = st.radio("ğŸ“Š ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ë³¼ê¹Œìš”?",
                                          options=radio_options,
                                          index=radio_index,
                                          horizontal=True)

                selected_group_level = group_labels[selected_label]

                # ì§‘ê³„ ë° ì‹œê°í™” (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                if selected_group_level in df_filtered.columns:
                    # í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„(df_filtered)ì—ì„œ ì‹œê°í™” ê¸°ì¤€(selected_group_level)ì— í•´ë‹¹í•˜ëŠ” ì¡°ì§ë§Œ ì§‘ê³„
                    view_df = df_filtered.dropna(subset=[selected_group_level])

                    question_counts = view_df[
                        selected_group_level].value_counts().reset_index()
                    question_counts.columns = ['ì¡°ì§ëª…', 'ì§ˆë¬¸ ìˆ˜']

                    user_counts = view_df.groupby(selected_group_level)[
                        'user_id'].nunique().reset_index()
                    user_counts.columns = ['ì¡°ì§ëª…', 'ì‚¬ìš©ì ìˆ˜']

                    org_stats = pd.merge(question_counts,
                                         user_counts,
                                         on='ì¡°ì§ëª…',
                                         how='left')
                    org_stats = org_stats.sort_values(
                        by='ì§ˆë¬¸ ìˆ˜', ascending=False).reset_index(drop=True)
                    org_stats.index = org_stats.index + 1

                    st.markdown("### ğŸ“Š ì§ˆë¬¸ ìˆ˜")
                    st.bar_chart(org_stats.set_index('ì¡°ì§ëª…')[['ì§ˆë¬¸ ìˆ˜']])

                    st.markdown("#### ğŸ“„ ì¡°ì§ë³„ ì§ˆë¬¸ ìˆ˜ ë° ì‚¬ìš©ì ìˆ˜")
                    st.dataframe(org_stats)
                else:
                    st.warning("ì„ íƒí•œ ê·¸ë£¹ ìˆ˜ì¤€ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                st.warning(
                    "âš ï¸ í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ (group_1, group_2, group_3, user_id).")

        with tab3:
            st.subheader("â“ ì§ˆë¬¸ í˜„í™©")

            # 1. ì›”ë³„ ì§ˆë¬¸ ìˆ˜ ì¶”ì´ (ì‹ ê·œ ì¶”ê°€)
            st.markdown("#### ğŸ“ˆ ì›”ë³„ ì§ˆë¬¸ ìˆ˜ ì¶”ì´")
            if 'regymdt' in df.columns:
                # ì›”ë³„ ì§‘ê³„ë¥¼ ìœ„í•´ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬ ë° ë‚ ì§œ í˜•ì‹ ë³€í™˜
                df_trend = df.copy()
                df_trend['regymdt'] = pd.to_datetime(df_trend['regymdt'],
                                                     errors='coerce')

                # ë‚ ì§œ ì •ë³´ê°€ ì—†ëŠ” í–‰ ì œê±°
                df_trend.dropna(subset=['regymdt'], inplace=True)

                if not df_trend.empty:
                    # ì›”(Month)ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¦¬ìƒ˜í”Œë§ ë° ì§ˆë¬¸ ìˆ˜ ê³„ì‚°
                    monthly_counts = df_trend.resample(
                        'M', on='regymdt').size().reset_index(name='ì§ˆë¬¸ ìˆ˜')

                    # ì°¨íŠ¸ì˜ xì¶• ë ˆì´ë¸”ì„ 'YYYY-MM' í˜•ì‹ìœ¼ë¡œ ë³€ê²½
                    monthly_counts['ì›”'] = monthly_counts[
                        'regymdt'].dt.strftime('%Y-%m')

                    # 'ì›”'ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ì—¬ ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
                    chart_data_monthly = monthly_counts.set_index('ì›”')

                    # ë¼ì¸ ì°¨íŠ¸ í‘œì‹œ
                    st.line_chart(chart_data_monthly[['ì§ˆë¬¸ ìˆ˜']])
                else:
                    st.info("í‘œì‹œí•  ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("âš ï¸ ì›”ë³„ ì¶”ì´ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” 'regymdt' ë‚ ì§œ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

            st.markdown("---")

            # 2. ì§ˆë¬¸ í˜„í™© Top 10 (ì°¨íŠ¸)
            #st.markdown("#### ğŸ† ì§ˆë¬¸ í˜„í™© Top 10 (ì°¨íŠ¸)")
            if 'chat_title' in df.columns:
                # Top 10 ë°ì´í„° ìƒì„± ë° ë°” ì°¨íŠ¸ ì‹œê°í™”
                #top_10_chart = df['chat_title'].value_counts().head(10)
                #st.bar_chart(top_10_chart)

                # 3. ì§ˆë¬¸ í˜„í™© Top 20 (í‘œ)
                st.markdown("#### ğŸ“„ ì§ˆë¬¸ ìœ í˜•ë³„ ìƒì„¸ ë°ì´í„°(Top 20)")
                top_20_table = df['chat_title'].value_counts().head(
                    20).reset_index()
                top_20_table.columns = ['ì§ˆë¬¸ ì£¼ì œ', 'ê±´ìˆ˜']
                top_20_table.index += 1
                #top_20_table.insert(0, 'ìˆœìœ„', top_20_table.index)
                st.dataframe(top_20_table)
            else:
                st.warning("âš ï¸ 'chat_title' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        with tab4:
            st.subheader("ğŸ§  ë‹µë³€ ë¶„ì„")
            # ì‘ë‹µìœ¨ í†µê³„ (ì´ì „ê³¼ ë™ì¼)
            if 'answer_yn' in df.columns:
                answer_counts = df['answer_yn'].value_counts()
                answered = answer_counts.get('Y', 0)
                unanswered = answer_counts.get('N', 0)
                total = answered + unanswered
                answered_pct = round(answered / total *
                                     100, 1) if total > 0 else 0
                unanswered_pct = round(unanswered / total *
                                       100, 1) if total > 0 else 0

                st.markdown(f"ì´ ì§ˆë¬¸ ìˆ˜: **{len(df)}**")
                st.markdown(f"âœ… ì‘ë‹µ: {answered}ê±´ ({answered_pct}%)")
                st.markdown(f"âŒ ë¯¸ì‘ë‹µ: {unanswered}ê±´ ({unanswered_pct}%)")
                st.markdown("---")

            # GPT ë¶„ì„ ë¡œì§ (ë²„íŠ¼ í†µí•©)
            if 'answer_yn' in df.columns and 'question' in df.columns:
                answered_df = df[df['answer_yn'] == 'Y']['question'].dropna()
                unanswered_df = df[df['answer_yn'] == 'N']['question'].dropna()

                # GPT ë¶„ì„ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼)
                def run_gpt_analysis(data_list, is_answered=True):
                    # ìƒ˜í”Œ ìˆ˜ë¥¼ 30ê°œë¡œ ê³ ì •í•˜ì—¬ API ë¹„ìš© ë° ì‹œê°„ ê´€ë¦¬
                    samples = data_list.sample(min(30, len(data_list)),
                                               random_state=42).tolist()
                    messages = [{
                        "role":
                        "system",
                        "content":
                        ("ì•„ë˜ëŠ” êµìœ¡ ì‹œìŠ¤í…œì—ì„œ " +
                         ("ì‘ë‹µëœ ì§ˆë¬¸ ëª©ë¡ì…ë‹ˆë‹¤." if is_answered else "ë¯¸ì‘ë‹µ ì§ˆë¬¸ ëª©ë¡ì…ë‹ˆë‹¤.")
                         + " ì´ ì§ˆë¬¸ë“¤ì„ ìœ í˜•ë³„ë¡œ ë¶„ë¥˜í•˜ê³ , " +
                         ("ì‘ë‹µëœ ì§ˆë¬¸ì˜ í•µì‹¬ íŠ¹ì§•ì„" if is_answered else "ë¯¸ì‘ë‹µëœ í•µì‹¬ ì‚¬ìœ ë¥¼") +
                         " ìš”ì•½ ë¶„ì„í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ëª…í™•í•œ ì¹´í…Œê³ ë¦¬ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.")
                    }, {
                        "role": "user",
                        "content": "\n".join(samples)
                    }]
                    try:
                        response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=messages,
                            temperature=0.3,
                        )
                        return response.choices[0].message.content
                    except Exception as e:
                        return f"âŒ GPT ë¶„ì„ ì˜¤ë¥˜: {e}"

                st.subheader("ğŸ¤– ì‘ë‹µ/ë¯¸ì‘ë‹µ ë¶„ì„í•˜ê¸°")

                # ë¶„ì„í•  ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ìˆì„ ê²½ìš°ì—ë§Œ ë²„íŠ¼ í‘œì‹œ
                if not answered_df.empty or not unanswered_df.empty:
                    if st.button("ChatGPTë¡œ ì‘ë‹µ/ë¯¸ì‘ë‹µ ë‚´ì—­ ë™ì‹œ ë¶„ì„í•˜ê¸°"):
                        with st.spinner(
                                "GPTê°€ ì „ì²´ ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):

                            # 1. ì‘ë‹µëœ ì§ˆë¬¸ ë¶„ì„
                            if not answered_df.empty:
                                st.markdown("### âœ… ì‘ë‹µëœ ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ê²°ê³¼")
                                result_answered = run_gpt_analysis(
                                    answered_df, is_answered=True)
                                st.markdown(result_answered)
                            else:
                                st.info("ë¶„ì„í•  ì‘ë‹µëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

                            st.markdown("---")  # ë¶„ì„ ê²°ê³¼ êµ¬ë¶„ì„ 

                            # 2. ë¯¸ì‘ë‹µ ì§ˆë¬¸ ë¶„ì„
                            if not unanswered_df.empty:
                                st.markdown("### âŒ ë¯¸ì‘ë‹µ ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ê²°ê³¼")
                                result_unanswered = run_gpt_analysis(
                                    unanswered_df, is_answered=False)
                                st.markdown(result_unanswered)
                            else:
                                st.info("ë¶„ì„í•  ë¯¸ì‘ë‹µ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

                        st.success("âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.info("ë¶„ì„í•  ì§ˆë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            else:
                st.warning("âš ï¸ 'answer_yn' ë˜ëŠ” 'question' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # --- ìˆ˜ì •ëœ tab5 ì½”ë“œ ---
        with tab5:
            st.subheader("ğŸ‘¤ ì´ìš©ì ë¶„ì„")
            st.markdown("---")

            if st.session_state.df_learning is None:
                st.info(
                    "ğŸ’¡ ìˆ˜ê°• ì´ë ¥ì„ í¬í•¨í•œ ì¢…í•© ë¶„ì„ì„ ì›í•˜ì‹œë©´, ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ìˆ˜ê°• ì´ë ¥ ì—…ë¡œë“œ í›„ í•¨ê»˜ ë¶„ì„'ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
                )

            if 'user_id' in df.columns:
                # --- â˜…â˜…â˜… í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ â˜…â˜…â˜… ---
                # 1. í”Œë ˆì´ìŠ¤í™€ë”(ì•ˆë‚´ ë¬¸êµ¬) ì •ì˜
                placeholder = "ë¶„ì„í•  ì´ìš©ìë¥¼ ì„ íƒí•˜ì„¸ìš”."

                # 2. ê¸°ì¡´ ì‚¬ìš©ì ëª©ë¡ ìƒì„±
                if 'user_name' in df.columns:
                    user_df = df[['user_id', 'user_name'
                                  ]].copy().dropna().drop_duplicates()
                    user_df['user_id'] = user_df['user_id'].astype(str)
                    user_df['display'] = user_df['user_id'] + " / " + user_df[
                        'user_name']
                    options_list = sorted(user_df['display'].unique())
                else:
                    options_list = sorted(
                        df['user_id'].dropna().astype(str).unique())

                # 3. í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ëª©ë¡ ë§¨ ì•ì— ì¶”ê°€í•˜ì—¬ selectbox ìƒì„±
                selected_display = st.selectbox(
                    "ğŸ‘¤ ì´ìš©ì ì„ íƒ",  # ë ˆì´ë¸”ì„ ë” ê°„ê²°í•˜ê²Œ ìˆ˜ì •
                    options=[placeholder] + options_list)

                # 4. í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì•„ë‹Œ, ì‹¤ì œ ì‚¬ìš©ìê°€ ì„ íƒë˜ì—ˆì„ ë•Œë§Œ ì•„ë˜ ë¶„ì„ ë¡œì§ ì‹¤í–‰
                if selected_display != placeholder:
                    selected_user_id = selected_display.split(
                        ' / '
                    )[0] if ' / ' in selected_display else selected_display
                    user_qa = df[df['user_id'].astype(str) == selected_user_id]

                    # --- 2. ì§ˆë¬¸/ì‘ë‹µ ìš”ì•½ ---
                    st.markdown("---")
                    st.markdown("### ğŸ“„ ì§ˆë¬¸/ì‘ë‹µ ìš”ì•½")
                    if not user_qa.empty:
                        total_q = len(user_qa)
                        answered_q = (user_qa['answer_yn'] == 'Y').sum(
                        ) if 'answer_yn' in user_qa.columns else 0
                        unanswered_q = (user_qa['answer_yn'] == 'N').sum(
                        ) if 'answer_yn' in user_qa.columns else 0
                        st.markdown(f"- ì´ ì§ˆë¬¸ ìˆ˜: **{total_q}** ê±´")
                        st.markdown(f"- ì‘ë‹µëœ ì§ˆë¬¸: **{answered_q}** ê±´")
                        st.markdown(f"- ë¯¸ì‘ë‹µ ì§ˆë¬¸: **{unanswered_q}** ê±´")
                        if 'regymdt' in user_qa.columns:
                            st.markdown(
                                f"- ë§ˆì§€ë§‰ ì§ˆë¬¸ì¼: **{user_qa['regymdt'].max().strftime('%Y-%m-%d')}**"
                            )
                    else:
                        st.info("í•´ë‹¹ ì‚¬ìš©ìì˜ ì§ˆë¬¸/ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                    # --- 3. í•™ìŠµ ì´ë ¥ ë¶„ì„ ---
                    st.markdown("---")
                    st.markdown("### ğŸ“š í•™ìŠµ ì´ë ¥ ë¶„ì„")

                    user_learning = pd.DataFrame()
                    if st.session_state.df_learning is not None:
                        df_learning = st.session_state.df_learning
                        if 'user_id' in df_learning.columns:
                            user_learning = df_learning[
                                df_learning['user_id'].astype(
                                    str) == selected_user_id]
                            if not user_learning.empty:
                                with st.expander(
                                        f"ğŸ“– í•™ìŠµ ì´ë ¥ ìƒì„¸ë³´ê¸° ({len(user_learning)}ê±´)"
                                ):
                                    st.dataframe(user_learning)
                            else:
                                st.warning(
                                    f"âš ï¸ ì—…ë¡œë“œëœ í•™ìŠµ ì´ë ¥ íŒŒì¼ì—ì„œ {selected_user_id} ë‹˜ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                                )
                        else:
                            st.error("âš ï¸ ì—…ë¡œë“œëœ í•™ìŠµ ì´ë ¥ íŒŒì¼ì— 'user_id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info(
                            "í‘œì‹œí•  í•™ìŠµ ì´ë ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…í•© ë¶„ì„ì„ ì›í•˜ì‹œë©´ ì‚¬ì´ë“œë°”ì—ì„œ ì´ë ¥ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                        )

                    # --- 4. í•™ìŠµ ì„±í–¥ ì¢…í•© ë¶„ì„ (GPT) ---
                    st.markdown("---")
                    st.markdown("### ğŸ§  í•™ìŠµ ì„±í–¥ ì¢…í•© ë¶„ì„ (by GPT)")
                    if st.button("ğŸ¤– ChatGPTë¡œ ë¶„ì„ ì‹¤í–‰í•˜ê¸°",
                                 key=f"gpt_user_{selected_user_id}"
                                 ):  # ì‚¬ìš©ìë³„ë¡œ ë²„íŠ¼ í‚¤ë¥¼ ë‹¤ë¥´ê²Œ í•˜ì—¬ ìƒíƒœ ìœ ì§€
                        if user_qa.empty:
                            st.warning("âš ï¸ ë¶„ì„í•  ì§ˆë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            with st.spinner("GPTê°€ ì‚¬ìš©ìì˜ í™œë™ ê¸°ë¡ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                                # (ì´í•˜ GPT ë¶„ì„ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
                                questions_list = user_qa['question'].dropna(
                                ).head(10).tolist()
                                base_data_info = "ì´ ë¶„ì„ì€ ì‚¬ìš©ìì˜ [ì§ˆë¬¸/ì‘ë‹µ ê¸°ë¡]ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤."
                                learning_titles_text = ""
                                if not user_learning.empty and 'title' in user_learning.columns:
                                    learning_titles = user_learning[
                                        'title'].dropna().head(15).tolist()
                                    if learning_titles:
                                        learning_titles_text, base_data_info = f'\n### 2. ì£¼ìš” í•™ìŠµ ì´ë ¥ (ìµœëŒ€ 15ê°œ):\n- {"- ".join(learning_titles)}', "ì´ ë¶„ì„ì€ ì‚¬ìš©ìì˜ [ì§ˆë¬¸/ì‘ë‹µ ê¸°ë¡]ê³¼ [í•™ìŠµ ì´ë ¥]ì„ ì¢…í•©í•˜ì—¬ ì œê³µë©ë‹ˆë‹¤."
                                prompt = f"""ë‹¤ìŒì€ í•œ ì§ì›ì˜ ì‹œìŠ¤í…œ ë‚´ í™œë™ ê¸°ë¡ì…ë‹ˆë‹¤.\n\n### 1. ì£¼ìš” ì§ˆë¬¸ ë‚´ì—­ (ìµœëŒ€ 10ê°œ):\n- {"- ".join(questions_list) if questions_list else "ì§ˆë¬¸ ê¸°ë¡ ì—†ìŒ"}\n{learning_titles_text}\n\n### [ë¶„ì„ ìš”ì²­]\nìœ„ì˜ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ, ì´ ì§ì›ì˜ **í•™ìŠµ ì„±í–¥ê³¼ ì£¼ìš” ê´€ì‹¬ì‚¬**ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.\në¶„ì„ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ 4ê°€ì§€ í•­ëª©ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ë‚˜ëˆ„ê³ , ê° í•­ëª©ì˜ ì œëª©ì„ ë°˜ë“œì‹œ ë¶™ì—¬ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\n1.  **ì£¼ìš” ê´€ì‹¬ ë¶„ì•¼**: ì–´ë–¤ ì£¼ì œì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ê³  í•™ìŠµí•˜ëŠ” ê²½í–¥ì´ ìˆëŠ”ê°€? (êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë‚˜ ì˜ì—­ ì œì‹œ)\n2.  **í•™ìŠµ íƒœë„**: ì§ˆë¬¸ê³¼ í•™ìŠµ ê¸°ë¡ì„ ë³¼ ë•Œ, ìê¸°ì£¼ë„ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ í•˜ëŠ”ê°€, ì•„ë‹ˆë©´ ì£¼ì–´ì§„ ì§€ì‹ì„ ìˆ˜ë™ì ìœ¼ë¡œ ìŠµë“í•˜ëŠ”ê°€? ì ê·¹ì„±, íƒêµ¬ì‹¬ ë“±ì„ í‰ê°€.\n3.  **ì§€ì‹ ê²©ì°¨(Knowledge Gap) ì¶”ì •**: (í•™ìŠµ ì´ë ¥ì´ ìˆë‹¤ë©´) ì§ˆë¬¸ ë‚´ìš©ê³¼ í•™ìŠµ ë‚´ìš©ì„ ë¹„êµí•˜ì—¬ ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•œ ë¶€ë¶„ì„ ì¶”ì •. (í•™ìŠµ ì´ë ¥ì´ ì—†ë‹¤ë©´) ì§ˆë¬¸ ë‚´ìš©ë§Œìœ¼ë¡œ íŒŒì•…ë˜ëŠ” ì§€ì‹ íƒêµ¬ ì˜ì—­ì´ë‚˜ ë¶€ì¡±í•œ ì ì„ ê¸°ìˆ .\n4.  **ì¢…í•© ìš”ì•½ ë° ì¶”ì²œ**: ìœ„ 1~3ë²ˆ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ ì§ì›ì˜ í•™ìŠµ ì„±í–¥ì„ 1~2 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ê²½ë ¥ ê°œë°œì— ë„ì›€ì´ ë  ë§Œí•œ í•™ìŠµ í™œë™ì´ë‚˜ ê³¼ì •ì„ ì¶”ì²œ."""
                                try:
                                    response = client.chat.completions.create(
                                        model="gpt-4-turbo-preview",
                                        messages=[{
                                            "role":
                                            "system",
                                            "content":
                                            "ë‹¹ì‹ ì€ ì„ì§ì›ì˜ í™œë™ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸ì˜ í•™ìŠµ ì„±í–¥ê³¼ ì—­ëŸ‰ ìˆ˜ì¤€ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ HRD ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì œì‹œëœ í˜•ì‹ì— ë§ì¶° ê° í•­ëª©ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤."
                                        }, {
                                            "role": "user",
                                            "content": prompt
                                        }],
                                        temperature=0.5)
                                    summary = response.choices[
                                        0].message.content
                                    st.success("âœ… GPT ë¶„ì„ ì™„ë£Œ!")
                                    st.info(base_data_info)
                                    st.markdown(summary)
                                except Exception as e:
                                    st.error(f"âŒ GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            else:
                st.warning("âš ï¸ ì´ìš©ì ë¶„ì„ì„ ì§„í–‰í•˜ë ¤ë©´ ì›ë³¸ ë°ì´í„°ì— 'user_id' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

        # --- ìˆ˜ì •ëœ tab6 ì½”ë“œ ---
        with tab6:
            st.header("ğŸ§ª ì‹¤í—˜ì‹¤: ì¡°ì§ ë° í‚¤ì›Œë“œ ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„")
            tab_org_search, tab_keyword_search = st.tabs(
                ["ğŸ¢ ì¡°ì§ ê²€ìƒ‰", "ğŸ” ë‹¨ì–´ ê²€ìƒ‰"])
            with tab_org_search:
                st.subheader("ì¡°ì§ë³„ ê´€ì‹¬ì‚¬ ë° í•™ìŠµ ë°©í–¥ ë¶„ì„")
                if all(col in df.columns
                       for col in ['group_1', 'group_2', 'group_3']):
                    org_full_list = df.apply(
                        lambda row:
                        f"{row['group_1']}/{row['group_2']}/{row['group_3']}",
                        axis=1).dropna().unique().tolist()
                    options_list = ['ì „ì²´'] + sorted(org_full_list)
                    selected_org_full = st.selectbox(
                        "ë¶„ì„í•  ì¡°ì§ì„ ì„ íƒí•˜ì„¸ìš” (ì˜ˆ: Aì„¼í„°/ê²½ì˜ì§€ì›ì‹¤/ì¸ì‚¬íŒ€)",
                        options=options_list)
                    df_filtered = df.copy()
                    if selected_org_full != 'ì „ì²´':
                        g1, g2, g3 = selected_org_full.split('/')
                        df_filtered = df[(df['group_1'] == g1)
                                         & (df['group_2'] == g2) &
                                         (df['group_3'] == g3)]
                    st.markdown("---")
                    if not df_filtered.empty:
                        st.subheader("â˜ï¸ ì£¼ìš” í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
                        text_data = ' '.join(
                            df_filtered['question'].fillna('').tolist())
                        if st.session_state.df_learning is not None:
                            org_user_ids = df_filtered['user_id'].unique()
                            org_learning_df = st.session_state.df_learning[
                                st.session_state.df_learning['user_id'].isin(
                                    org_user_ids)]
                            if not org_learning_df.empty and 'title' in org_learning_df.columns:
                                text_data += ' ' + ' '.join(
                                    org_learning_df['title'].fillna(
                                        '').tolist())
                                st.info("ì§ˆë¬¸ ë‚´ìš©ê³¼ ìˆ˜ê°•í•œ ê°•ì¢Œëª…ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        if not text_data.strip():
                            st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            wordcloud = WordCloud(
                                font_path=FONT_PATH,
                                width=800,
                                height=400,
                                background_color='white').generate(text_data)
                            fig, ax = plt.subplots()
                            ax.imshow(wordcloud, interpolation='bilinear')
                            ax.axis("off")
                            st.pyplot(fig)
                        st.markdown("---")
                        if st.button("ğŸ¤– GPTë¡œ ì¡°ì§ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"):
                            with st.spinner(
                                    "GPTê°€ ì¡°ì§ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  HRD ê´€ì ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œ ì¤‘ì…ë‹ˆë‹¤..."
                            ):
                                top_keywords = Counter([
                                    w for w in text_data.split() if len(w) > 1
                                ]).most_common(30)
                                keyword_text = ", ".join(
                                    [w for w, _ in top_keywords])
                                top_questions_text = "\n- ".join(
                                    df_filtered['chat_title'].value_counts(
                                    ).head(5).index.tolist()
                                ) if 'chat_title' in df_filtered else "ì§ˆë¬¸ ì£¼ì œ ë°ì´í„° ì—†ìŒ"
                                learning_summary_text = " (í•™ìŠµ ì´ë ¥ ë°ì´í„° ì—†ìŒ)"
                                if st.session_state.df_learning is not None and not org_learning_df.empty:
                                    top_courses = org_learning_df[
                                        'title'].value_counts().head(
                                            5).index.tolist()
                                    learning_summary_text = f"### 3. ì£¼ìš” í•™ìŠµ ê³¼ì • Top 5:\n- " + "\n- ".join(
                                        top_courses)
                                prompt = f"""ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ì˜ HRD ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¡°ì§ì˜ íŠ¹ì„±ì„ ì‹¬ì¸µ ë¶„ì„í•˜ê³  ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n### ë¶„ì„ ëŒ€ìƒ ì¡°ì§: {selected_org_full}\n\n### 1. ì£¼ìš” ì§ˆë¬¸/í•™ìŠµ í‚¤ì›Œë“œ: {keyword_text}\n### 2. ì£¼ìš” ì§ˆë¬¸ ì£¼ì œ: {top_questions_text}\n{learning_summary_text}\n---\n### [ë¶„ì„ ìš”ì²­]\nìœ„ ë°ì´í„°ë¥¼ HRD ê´€ì ì—ì„œ ì¢…í•© ë¶„ì„í•˜ì—¬, ë°˜ë“œì‹œ ì•„ë˜ 4ê°€ì§€ í•­ëª©ì˜ ì œëª©ì„ í¬í•¨í•˜ì—¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n1. **ì¡°ì§ì˜ ì£¼ìš” ê´€ì‹¬ì‚¬ ë° í˜„í™©**: êµ¬ì„±ì›ë“¤ì´ í˜„ì¬ ê°€ì¥ ê´€ì‹¬ì„ ê°–ëŠ” ì—…ë¬´ ë¶„ì•¼ë‚˜ ì£¼ì œëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?\n2. **ì—…ë¬´/ì—­ëŸ‰ ê´€ë ¨ ì£¼ìš” ì´ìŠˆ**: ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ë“¤ì„ í†µí•´ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì´ ì¡°ì§ì˜ ì—…ë¬´ìƒ ì–´ë ¤ì›€(pain point)ì´ë‚˜ ì—­ëŸ‰ì  ê³µë°±ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\n3. **ì§€ì‹ ê²©ì°¨ ë° í•„ìš” ì—­ëŸ‰**: êµ¬ì„±ì›ë“¤ì´ ë³´ìœ í•œ ì§€ì‹(í•™ìŠµ ì´ë ¥)ê³¼ ê¶ê¸ˆí•´í•˜ëŠ” ì§€ì‹(ì§ˆë¬¸) ì‚¬ì´ì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì´ë©°, ì–´ë–¤ ì—­ëŸ‰ì„ ì¶”ê°€ ê°œë°œí•´ì•¼ í•©ë‹ˆê¹Œ?\n4. **HRD ê´€ì ì˜ ì¢…í•© ì œì–¸**: ì´ ì¡°ì§ì˜ ì„±ê³¼ í–¥ìƒê³¼ ì—­ëŸ‰ ê°œë°œì„ ìœ„í•´ ì–´ë–¤ êµìœ¡ í”„ë¡œê·¸ë¨ ì„¤ê³„ë‚˜ í•™ìŠµ ë¬¸í™” ì¡°ì„±ì´ íš¨ê³¼ì ì¼ì§€ êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œ 1~2ê°€ì§€ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”."""
                                try:
                                    response = client.chat.completions.create(
                                        model="gpt-4-turbo-preview",
                                        messages=[{
                                            "role": "user",
                                            "content": prompt
                                        }],
                                        temperature=0.4)
                                    summary = response.choices[
                                        0].message.content
                                    st.subheader("ğŸ§  GPT ì¡°ì§ ë¶„ì„ ë¦¬í¬íŠ¸")
                                    st.markdown(summary)
                                except Exception as e:
                                    st.error(f"âŒ GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                else:
                    st.warning(
                        "âš ï¸ ì¡°ì§ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì›ë³¸ ë°ì´í„°ì— 'group_1', 'group_2', 'group_3' ì»¬ëŸ¼ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."
                    )
            with tab_keyword_search:
                st.subheader("í‚¤ì›Œë“œ ê´€ë ¨ ì¡°ì§ ë° í•™ìŠµ ë¶„ì„")
                keyword = st.text_input("ê²€ìƒ‰í•  ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                                        key="lab_keyword_input")
                st.markdown("---")
                if keyword:
                    contains_mask = df['question'].str.contains(
                        keyword, na=False) | df['answer'].str.contains(
                            keyword, na=False)
                    df_filtered_keyword = df[contains_mask]
                    if not df_filtered_keyword.empty:
                        st.success(
                            f"'{keyword}' í‚¤ì›Œë“œê°€ í¬í•¨ëœ **{len(df_filtered_keyword)}**ê±´ì˜ ëŒ€í™”ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                        )
                        if 'group_1' in df_filtered_keyword.columns:
                            st.subheader(
                                f"ğŸ… '{keyword}' í‚¤ì›Œë“œ ì–¸ê¸‰ ì¡°ì§ Top 10 (ì„¼í„° ê¸°ì¤€)")
                            top_orgs = df_filtered_keyword[
                                'group_1'].value_counts().head(10)
                            st.dataframe(top_orgs)
                        st.markdown("---")
                        with st.expander("ğŸ“‚ ê´€ë ¨ ì§ˆë¬¸ ì˜ˆì‹œ ë³´ê¸°"):
                            st.dataframe(df_filtered_keyword[[
                                'question', 'answer', 'group_1', 'group_2'
                            ]].head(10))
                        st.markdown("---")
                        st.subheader("ğŸ“š í‚¤ì›Œë“œ ì–¸ê¸‰ êµ¬ì„±ì›ì˜ ìˆ˜ê°• í˜„í™©")
                        if st.session_state.df_learning is not None:
                            df_learning = st.session_state.df_learning

                            if 'title' in df_learning.columns:
                                keyword_user_ids = df_filtered_keyword[
                                    'user_id'].unique()
                                related_learning = df_learning[df_learning[
                                    'user_id'].isin(keyword_user_ids)]

                                if not related_learning.empty:
                                    # --- â˜…â˜…â˜… ìš”ì²­í•˜ì‹  ìš”ì•½ ì§€í‘œ ê³„ì‚° ë° í‘œì‹œ ë¶€ë¶„ â˜…â˜…â˜… ---
                                    total_courses = related_learning[
                                        'title'].nunique()
                                    total_enrollments = len(related_learning)
                                    total_users = related_learning[
                                        'user_id'].nunique()

                                    # st.columnsë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€í‘œë¥¼ ê°€ë¡œë¡œ ë‚˜ì—´
                                    col1, col2, col3 = st.columns(3)
                                    col1.metric("ì´ ê°•ì¢Œ ìˆ˜", f"{total_courses} ê°œ")
                                    col2.metric("ì´ ìˆ˜ê°• íšŸìˆ˜",
                                                f"{total_enrollments} íšŒ")
                                    col3.metric("ì´ ìˆ˜ê°• ì¸ì›", f"{total_users} ëª…")

                                    st.markdown("---")  # ìš”ì•½ ì§€í‘œì™€ í…Œì´ë¸” ì‚¬ì´ êµ¬ë¶„ì„ 

                                    # í‘œ ë°ì´í„° ê°€ê³µ
                                    course_counts = related_learning[
                                        'title'].value_counts().reset_index()
                                    course_counts.columns = ['ê°•ì¢Œëª…', 'ì´ ìˆ˜ê°• íšŸìˆ˜']

                                    if 'group_1' in df.columns:
                                        user_to_org_map = df[[
                                            'user_id', 'group_1'
                                        ]].drop_duplicates().set_index(
                                            'user_id')['group_1']
                                        related_learning_with_org = related_learning.copy(
                                        )
                                        related_learning_with_org[
                                            'group_1'] = related_learning_with_org[
                                                'user_id'].map(user_to_org_map)
                                        related_learning_with_org.dropna(
                                            subset=['title', 'group_1'],
                                            inplace=True)

                                        org_counts_by_course = related_learning_with_org.groupby(
                                            ['title',
                                             'group_1']).size().reset_index(
                                                 name='org_count')
                                        top_org_by_course = org_counts_by_course.sort_values(
                                            'org_count',
                                            ascending=False).drop_duplicates(
                                                'title')
                                        top_org_by_course[
                                            'ìµœë‹¤ ìˆ˜ê°• ì¡°ì§(íšŸìˆ˜)'] = top_org_by_course.apply(
                                                lambda row:
                                                f"{row['group_1']} ({row['org_count']}íšŒ)",
                                                axis=1)

                                        final_table = pd.merge(
                                            course_counts,
                                            top_org_by_course[[
                                                'title', 'ìµœë‹¤ ìˆ˜ê°• ì¡°ì§(íšŸìˆ˜)'
                                            ]].rename(
                                                columns={'title': 'ê°•ì¢Œëª…'}),
                                            on='ê°•ì¢Œëª…',
                                            how='left')
                                        st.dataframe(final_table)
                                    else:
                                        st.warning(
                                            "ì¡°ì§ë³„ ìˆ˜ê°• í˜„í™©ì„ ë³´ë ¤ë©´ ì›ë³¸ ì§ˆë¬¸/ë‹µë³€ ë°ì´í„°ì— 'group_1' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
                                        )
                                        st.dataframe(course_counts)
                            else:
                                st.info("í‚¤ì›Œë“œë¥¼ ì–¸ê¸‰í•œ êµ¬ì„±ì›ë“¤ì˜ ìˆ˜ê°• ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ìˆ˜ê°• ì´ë ¥ì„ ì—…ë¡œë“œí•˜ë©´, í‚¤ì›Œë“œì™€ ì—°ê´€ëœ í•™ìŠµ í˜„í™©ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"'{keyword}'ë¥¼ í¬í•¨í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    st.info("ğŸ“‚ ì‹œì‘í•˜ë ¤ë©´ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
